{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9aed78",
   "metadata": {},
   "source": [
    "## Chat with linkedin (with evaluator)\n",
    "\n",
    "In this notebook, I create a chatbot that enables chatting with my linkedin profile.\n",
    "\n",
    "Additionally, the responses by the chatbot are **evaluated** by an evaluator LLM before they are displayed to the user. \n",
    "\n",
    "If the response isn't satisfactory, it is refined before ensuring satisfactoriness before returning to the user.\n",
    "\n",
    "At a high level, following steps are followed\n",
    "\n",
    "0. Base application (prompt, data etc.)\n",
    "1. Create a custom pydantic class to parse evaluator responses.\n",
    "2. Create evaluator prompt (system, user role messages)\n",
    "3. Choose evaluator LLM & create it's client\n",
    "4. Create a function that evaluates the response and returns object of class in 1.\n",
    "5. Create a function that optimizes (reruns) reponse from base LLM\n",
    "6. Create final chat function\n",
    "7. Launch gradio chatInterface\n",
    "\n",
    "### Base application (prompt, data etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9caa11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PERSONAL\\Github\\miscellaneous-tasks\\chat-with-linkedin-profile\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c38e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "\n",
    "reader = PdfReader(\"linkedin_docs/linkedin_pdf_cg.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "        \n",
    "with open(\"linkedin_docs/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "    \n",
    "name = \"Chaitanya Gokhale\"\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b66bd9",
   "metadata": {},
   "source": [
    "### Create custom pydantic evaluator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690be398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluator(BaseModel):\n",
    "    is_correct: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b838c",
   "metadata": {},
   "source": [
    "### Create evaluator prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac267b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator LLM. Our base task is a chatbot which enables a discussion of the user with the linkedin profile \\\n",
    "    and personality of the {name} who is a person. Your task is to ensure that the response of this chatbot is appropriate using a criteria \\\n",
    "    The criteria is that the response should be in english, professional and high in relevance to the core topic.\"\n",
    "    \n",
    "def get_evaluator_user_prompt(base_llm_response):     \n",
    "    evaluator_user_prompt = f\"Following is the response from our base LLM. {base_llm_response}. \\\n",
    "        As mentioned in the system prompt, you are an evaluator LLM and your job is to evaluate if the response from the other LLM \\\n",
    "        is as expected. The criteria is that the response should be in english, professional and high in relevance to the core topic. \\\n",
    "        Please respond with two values : true or false and a short reasoning for true/false response.\"\n",
    "    return evaluator_user_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefb468",
   "metadata": {},
   "source": [
    "### Choose evaluator LLM and create its client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd2b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a96ef",
   "metadata": {},
   "source": [
    "### Create evaluate function\n",
    "\n",
    "A function that takes in the response of base llm and returns the Evaluator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55cb7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(base_llm_response, evaluator_system_prompt) -> Evaluator:\n",
    "    evaluator_user_prompt = get_evaluator_user_prompt(base_llm_response)\n",
    "    evaluator_messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}, {\"role\": \"user\", \"content\": evaluator_user_prompt}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-flash\", messages=evaluator_messages, response_format=Evaluator)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6b4bf",
   "metadata": {},
   "source": [
    "### Create a rerun/optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ec5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(base_llm_response, feedback, user_query):\n",
    "    optimizer_system_prompt = system_prompt\n",
    "    optimizer_system_prompt += f\"\\n\\n Your previous response did not satisfy the evaluation criteria i.e. was rejected. \\\n",
    "        Your response was {base_llm_response}.\\\n",
    "        Following was the reason as to why the criteria was not satisfied {feedback}.\\\n",
    "        Your task now is to re-evaluate your response and send a response that makes sure that your original task is catered to \\\n",
    "        as well as the response should eliminate the reason why the evaluation was rejected.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": optimizer_system_prompt}, {\"role\": \"user\", \"content\": user_query}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89404283",
   "metadata": {},
   "source": [
    "### Create a final chat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2594c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    evaluate_reply = evaluate(reply, evaluator_system_prompt=evaluator_system_prompt)\n",
    "    if evaluate_reply.is_correct:\n",
    "        print(\"Reply evaluated : correct\")\n",
    "    else:\n",
    "        print(f\"Reply evaluated : wrong.\\n\\nFeedback : {evaluate_reply.feedback}\")\n",
    "        reply = optimizer(reply)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086dea4",
   "metadata": {},
   "source": [
    "### Launch gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c87106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply evaluated : correct\n",
      "Reply evaluated : correct\n",
      "Reply evaluated : correct\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-with-linkedin-profile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
